{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from string import punctuation\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "access_token = os.getenv(\"HF_TOKEN1\")\n",
    "if access_token is None:\n",
    "    raise ValueError(f\"HF access_token is None. Please set up token in system environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################ Start of Utility Functions ################################################\n",
    "\n",
    "# def query(payload):\n",
    "# \tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "# \treturn response.json()\n",
    "\n",
    "def generate_sentiment_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the text enclosed in angle brackets, \n",
    "            determine if it is positive, neutral, or negative, and \n",
    "            return the answer as the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "            For example: \n",
    "            <Youâ€™ve had over a month to get this finalized ! Why are things delayed ?> = negative\n",
    "            <WOW! Drone Delivery Startup, @zipline Raises $25m To Expand Its Operations In Africa> = positive\n",
    "            <The environment can and has survived much hotter conditions.> = neutral\n",
    "\n",
    "            <{text}> = \"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_emotion_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the emotion of the text enclosed in angle brackets, \n",
    "            determine if it is happiness, anger, disgust, fear, sadness, surprise or other emotion, and \n",
    "            return the answer as the corresponding emotion label \"happiness\" or \"anger\" or \"disgust\" or \"fear\" or \"sadness\" or \"surprise\" or \"other\".\n",
    "            For example:\n",
    "            <Youâ€™ve had over a month to get this finalized ! Why are things delayed ?> = anger\n",
    "            <WOW! Drone Delivery Startup, @zipline Raises $25m To Expand Its Operations In Africa> = surprise\n",
    "            <The environment can and has survived much hotter conditions.> = other\n",
    "\n",
    "            <{text}> = \"\"\".strip()\n",
    "\n",
    "def generate_emotion_and_sentiment_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the emotion and sentiment of the text enclosed in angle brackets. \n",
    "            For emotion, determine if it is happiness, anger, disgust, fear, sadness, surprise or other emotion.\n",
    "            For sentiment, determine if it is happiness, anger, disgust, fear, sadness, surprise or other emotion.\n",
    "            Return the answer as \"emotion\" \"sentiment\" where emotion is from the corresponding emotion label \"happiness\" or \"anger\" or \"disgust\" \n",
    "            or \"fear\" or \"sadness\" or \"surprise\" or \"other\"; and sentiment is from the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\"; \n",
    "            emotion followed by sentiment, separated by a space.\n",
    "            \n",
    "            For example:\n",
    "            <Youâ€™ve had over a month to get this finalized ! Why are things delayed ?> = anger negative\n",
    "            <WOW! Drone Delivery Startup, @zipline Raises $25m To Expand Its Operations In Africa> = surprise positive\n",
    "            <The environment can and has survived much hotter conditions.> = other neutral\n",
    "\n",
    "            <{text}> = \"\"\".strip()\n",
    "\n",
    "def extract_label(generated_text, target_labels):\n",
    "    \"\"\"Extract from the generated text the first label that is defined in the set of target labels\"\"\"\n",
    "    tokens = generated_text.split()\n",
    "    for token in tokens:\n",
    "        token = token.strip(punctuation)\n",
    "        if token.lower() in target_labels:\n",
    "            return token.lower()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def predict(model, tokenizer, datafile, outfile1, outfile2):\n",
    "\n",
    "    pipe = pipeline(\n",
    "        task=\"text-generation\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=64,\n",
    "        # device=2,\n",
    "        device_map=\"auto\",\n",
    "        # padding=True,\n",
    "    )\n",
    "\n",
    "    with open(datafile, 'r', newline='') as infile, open(outfile1, 'w', newline='') as out_file1, open(outfile2, 'w', newline='') as out_file2:\n",
    "        csv_reader = csv.DictReader(infile)\n",
    "        \n",
    "        fieldnames1 = csv_reader.fieldnames + [\"llama3_sentiment\", \"llama3_emotion\"]\n",
    "        csv_writer1 = csv.DictWriter(out_file1, fieldnames=fieldnames1)\n",
    "        csv_writer1.writeheader()\n",
    "\n",
    "        fieldnames2 = csv_reader.fieldnames + [\"llama3_raw\"]  # changed from 2 separate columns for emotion and sentiment\n",
    "        csv_writer2 = csv.DictWriter(out_file2, fieldnames=fieldnames2)\n",
    "        csv_writer2.writeheader()\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        last_time = start_time\n",
    "        counter = 1\n",
    "        MAX_ROW = 2\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            if counter > MAX_ROW: break\n",
    "            prompt = generate_emotion_and_sentiment_prompt(row['text'])\n",
    "\n",
    "            print(\"Inferencing row\", counter)\n",
    "            # print(\"tokenized input:\", tokenizer(prompt, padding=\"max_length\", max_length=512))\n",
    "            output = pipe(prompt)\n",
    "            # print(f\"inference time: {(datetime.now()-last_time).total_seconds()}s\")\n",
    "            llama3_sentiment = None\n",
    "            llama3_emotion = None\n",
    "\n",
    "            raw = output[0][\"generated_text\"].split(prompt)[-1]\n",
    "            llama3_sentiment = extract_label(raw, target_labels=[\"positive\", \"negative\", \"neutral\"])\n",
    "            llama3_emotion = extract_label(raw, target_labels=[\"happiness\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"])\n",
    "\n",
    "            # print(output[0][\"generated_text\"])\n",
    "            # print(llama3_sentiment)\n",
    "            # print(llama3_emotion)\n",
    "\n",
    "            row[\"llama3_sentiment\"] = llama3_sentiment\n",
    "            row[\"llama3_emotion\"] = llama3_emotion\n",
    "            # print(row)\n",
    "            csv_writer1.writerow(row)\n",
    "            \n",
    "            row.pop(\"llama3_sentiment\", None)\n",
    "            row.pop(\"llama3_emotion\", None)\n",
    "            row[\"llama3_raw\"] = raw\n",
    "            csv_writer2.writerow(row)\n",
    "\n",
    "            t_delta = (datetime.now()-last_time).total_seconds()*1000\n",
    "            print(\"Time elapsed (ms): \", t_delta)\n",
    "            last_time = datetime.now()\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Total time elapsed (s): {(last_time-start_time).total_seconds()}\")\n",
    "\n",
    "def predict(model, tokenizer, df):\n",
    "    pipe = pipeline(\n",
    "        task=\"text-generation\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=64,\n",
    "        # device=2,\n",
    "        device_map=\"auto\",\n",
    "        # padding=True,\n",
    "    )\n",
    "    output = pd.DataFrame(columns=[\"emotion\", \"sentiment\"])\n",
    "    sentiments = []\n",
    "    emotions = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = row['text']\n",
    "        output = pipe(prompt)\n",
    "        raw = output[0][\"generated_text\"].split(prompt)[-1]\n",
    "        llama3_sentiment = extract_label(raw, target_labels=[\"positive\", \"negative\", \"neutral\"])\n",
    "        llama3_emotion = extract_label(raw, target_labels=[\"happiness\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"])\n",
    "        sentiments.append(llama3_sentiment)\n",
    "        emotions.append(llama3_emotion)\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"emotion\": emotions,\n",
    "            \"sentiment\": sentiments\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # print(output.describe())\n",
    "    return output\n",
    "\n",
    "########################################## End of Utility Functions ##############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datafile = \"data/drone/masked_all_tweets.csv\"\n",
    "# outfile1 = \"output/drone/local_llama3_8B/test/masked_all_tweets_llama3.csv\"\n",
    "# outfile2 = \"output/drone/local_llama3_8B/test/masked_all_tweets_llama3_raw.csv\"\n",
    "datafile = \"data/drone/drone_tweets_qc_annotated.csv\"\n",
    "df = pd.read_csv(datafile, encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "emotions = [\"happiness\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"]\n",
    "sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "sent_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "emotion_mapping = {\"happiness\":0, \"anger\":1, \"disgust\":2, \"fear\":3, \"sadness\":4, \"surprise\":5, \"other\":6}\n",
    "\n",
    "df[\"emotion\"] = df[\"golden emotion\"]\n",
    "df[\"sentiment\"] = df[\"golden sentiment\"]\n",
    "df = df[[\"text\",\"emotion\",\"sentiment\"]]\n",
    "df[\"text\"] = df[\"text\"].map(generate_emotion_and_sentiment_prompt)\n",
    "df_train, df_test = train_test_split(df, test_size=0.15, random_state=88)\n",
    "\n",
    "emotion_df = df_train.rename(columns={\"emotion\": \"label\"})\n",
    "sentiment_df = df_train.rename(columns={\"sentiment\": \"label\"})\n",
    "\n",
    "emotion_dataset = Dataset.from_pandas(emotion_df).remove_columns(\"__index_level_0__\")\n",
    "sentiment_dataset = Dataset.from_pandas(sentiment_df).remove_columns(\"__index_level_0__\")\n",
    "\n",
    "\n",
    "# pred_path = \"output/drone/local_llama3_8B/few_shots/masked_all_tweets_llama3.csv\"\n",
    "# preds_df = pd.read_csv(pred_path)\n",
    "# preds_df[\"emotion\"] = preds_df[\"llama3_emotion\"]\n",
    "# preds_df[\"sentiment\"] = preds_df[\"llama3_sentiment\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataset = emotion_dataset.train_test_split(test_size=0.2, seed=88)\n",
    "sentiment_dataset = sentiment_dataset.train_test_split(test_size=0.2, seed=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.71s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:355: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204/204 [00:00<00:00, 2469.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 2168.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cuda\"\n",
    "\n",
    "cache_dir = \"cache/llama3_8B\"\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=compute_dtype,\n",
    "    token=access_token,\n",
    "    # quantization_config=bnb_config, \n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "prepare_model_for_kbit_training(model=model)\n",
    "\n",
    "# model.to(device)\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.train()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True,\n",
    "    token=access_token,\n",
    "    cache_dir=cache_dir,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  # ã€€left for inference\n",
    "\n",
    "output_dir=\"output/drone/local_llama3_8B/trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=3,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=10,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    # report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=emotion_dataset[\"train\"],\n",
    "    eval_dataset=emotion_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "\n",
    "# predict(model, tokenizer, datafile, outfile1, outfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 04:39, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.530100</td>\n",
       "      <td>0.473508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.460372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=0.60627303759257, metrics={'train_runtime': 283.528, 'train_samples_per_second': 2.159, 'train_steps_per_second': 0.265, 'total_flos': 7110656443662336.0, 'train_loss': 0.60627303759257, 'epoch': 2.9411764705882355})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "for _ in range(100):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.80s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./finetuned_llama3_8B/tokenizer_config.json',\n",
       " './finetuned_llama3_8B/special_tokens_map.json',\n",
       " './finetuned_llama3_8B/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = output_dir\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=device,\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./finetuned_llama3_8B\",safe_serialization=True, max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./finetuned_llama3_8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        emotions sentiments\n",
      "count         45         45\n",
      "unique         5          3\n",
      "top     surprise   positive\n",
      "freq          25         24\n"
     ]
    }
   ],
   "source": [
    "preds = predict(merged_model, tokenizer, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "\n",
    "# def map_func(x):\n",
    "#     return mapping.get(x, 1)\n",
    "\n",
    "def evaluate(y_true, y_pred, labels):\n",
    "\n",
    "    y_true = y_true.tolist()\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.5f}')\n",
    "    \n",
    "    \n",
    "    for label in labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.5f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, digits=5)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11111\n",
      "Accuracy for label happiness: 0.20000\n",
      "Accuracy for label anger: nan\n",
      "Accuracy for label disgust: 0.00000\n",
      "Accuracy for label fear: nan\n",
      "Accuracy for label sadness: nan\n",
      "Accuracy for label surprise: nan\n",
      "Accuracy for label other: 0.10526\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger    0.00000   0.00000   0.00000         0\n",
      "     disgust    0.00000   0.00000   0.00000         2\n",
      "   happiness    1.00000   0.20000   0.33333         5\n",
      "       other    1.00000   0.10526   0.19048        38\n",
      "    surprise    0.00000   0.00000   0.00000         0\n",
      "\n",
      "    accuracy                        0.11111        45\n",
      "   macro avg    0.40000   0.06105   0.10476        45\n",
      "weighted avg    0.95556   0.11111   0.19788        45\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  1  0  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0 10  2  0  0 22  4]]\n",
      "Accuracy: 0.48889\n",
      "Accuracy for label positive: 0.85714\n",
      "Accuracy for label negative: 1.00000\n",
      "Accuracy for label neutral: 0.31250\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative    0.54545   1.00000   0.70588         6\n",
      "     neutral    1.00000   0.31250   0.47619        32\n",
      "    positive    0.25000   0.85714   0.38710         7\n",
      "\n",
      "    accuracy                        0.48889        45\n",
      "   macro avg    0.59848   0.72321   0.52306        45\n",
      "weighted avg    0.82273   0.48889   0.49296        45\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  1  0]\n",
      " [ 0  6  0]\n",
      " [18  4 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(df_test['emotion'], preds['emotions'], emotions)\n",
    "evaluate(df_test['sentiment'], preds['sentiments'], sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from string import punctuation\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./finetuned_llama3_8B/\")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./finetuned_llama3_8B/\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, tokenizer, df):\n",
    "    pipe = pipeline(\n",
    "        task=\"text-generation\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=64,\n",
    "        # device=2,\n",
    "        device_map=\"auto\",\n",
    "        # padding=True,\n",
    "    )\n",
    "    output = pd.DataFrame(columns=[\"emotion\", \"sentiment\"])\n",
    "    sentiments = []\n",
    "    emotions = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = row['text']\n",
    "        output = pipe(prompt)\n",
    "        raw = output[0][\"generated_text\"].split(prompt)[-1]\n",
    "        llama3_sentiment = extract_label(raw, target_labels=[\"positive\", \"negative\", \"neutral\"])\n",
    "        llama3_emotion = extract_label(raw, target_labels=[\"happiness\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"])\n",
    "        sentiments.append(llama3_sentiment)\n",
    "        emotions.append(llama3_emotion)\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"emotion\": emotions,\n",
    "            \"sentiment\": sentiments\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # print(output.describe())\n",
    "    return output\n",
    "\n",
    "# def map_func(x):\n",
    "#     return mapping.get(x, 1)\n",
    "\n",
    "def evaluate(y_true, y_pred, labels):\n",
    "\n",
    "    y_true = y_true.tolist()\n",
    "    y_pred = y_pred.tolist()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.5f}')\n",
    "    \n",
    "    \n",
    "    for label in labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.5f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, digits=5)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emotion_and_sentiment_prompt(text):\n",
    "    return f\"\"\"\n",
    "            Analyze the emotion and sentiment of the text enclosed in angle brackets. \n",
    "            For emotion, determine if it is happiness, anger, disgust, fear, sadness, surprise or other emotion.\n",
    "            For sentiment, determine if it is happiness, anger, disgust, fear, sadness, surprise or other emotion.\n",
    "            Return the answer as \"emotion\" \"sentiment\" where emotion is from the corresponding emotion label \"happiness\" or \"anger\" or \"disgust\" \n",
    "            or \"fear\" or \"sadness\" or \"surprise\" or \"other\"; and sentiment is from the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\"; \n",
    "            emotion followed by sentiment, separated by a space.\n",
    "            \n",
    "            For example:\n",
    "            <Youâ€™ve had over a month to get this finalized ! Why are things delayed ?> = anger negative\n",
    "            <WOW! Drone Delivery Startup, @zipline Raises $25m To Expand Its Operations In Africa> = surprise positive\n",
    "            <The environment can and has survived much hotter conditions.> = other neutral\n",
    "\n",
    "            <{text}> = \"\"\".strip()\n",
    "\n",
    "datafile = \"data/drone/responses/all_tweets_full_responses.csv\"\n",
    "df = pd.read_csv(datafile, encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "emotions = [\"happiness\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"]\n",
    "sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "sent_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "emotion_mapping = {\"happiness\":0, \"anger\":1, \"disgust\":2, \"fear\":3, \"sadness\":4, \"surprise\":5, \"other\":6}\n",
    "\n",
    "df[\"emotion\"] = df[\"voted_emotion\"]\n",
    "df[\"sentiment\"] = df[\"voted_sentiment\"]\n",
    "df = df[[\"text\",\"emotion\",\"sentiment\"]]\n",
    "df[\"text\"] = df[\"text\"].map(generate_emotion_and_sentiment_prompt)\n",
    "df_train, df_test = train_test_split(df, test_size=0.7, random_state=88, stratify=df['emotion'])\n",
    "\n",
    "emotion_df = df_train.rename(columns={\"emotion\": \"label\"})\n",
    "sentiment_df = df_train.rename(columns={\"sentiment\": \"label\"})\n",
    "\n",
    "emotion_dataset = Dataset.from_pandas(emotion_df).remove_columns(\"__index_level_0__\")\n",
    "sentiment_dataset = Dataset.from_pandas(sentiment_df).remove_columns(\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.to_csv(\"data/drone/tweets_emotion_train.csv\")\n",
    "sentiment_df.to_csv(\"data/drone/tweets_sentiment_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load a dataset from the Hugging Face Hub\n",
    "datafile = \"data/drone/responses/all_tweets_full_responses.csv\"\n",
    "df = pd.read_csv(datafile, encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "df[\"emotion\"] = df[\"voted_emotion\"]\n",
    "df[\"sentiment\"] = df[\"voted_sentiment\"]\n",
    "df = df[[\"text\",\"emotion\",\"sentiment\"]]\n",
    "emotion_df = df.rename(columns={\"emotion\": \"label\"})\n",
    "sentiment_df = df.rename(columns={\"sentiment\": \"label\"})\n",
    "\n",
    "emotion_df_train, emotion_df_test = train_test_split(emotion_df, test_size=0.7, random_state=88, stratify=df['emotion'])\n",
    "sentiment_df_train, sentiment_df_test = train_test_split(sentiment_df, test_size=0.7, random_state=88, stratify=df['sentiment'])\n",
    "\n",
    "emotion_ds_train = Dataset.from_pandas(emotion_df_train).remove_columns(\"__index_level_0__\")\n",
    "emotion_ds_test = Dataset.from_pandas(emotion_df_test).remove_columns(\"__index_level_0__\")\n",
    "sentiment_ds_train = Dataset.from_pandas(sentiment_df_train).remove_columns(\"__index_level_0__\")\n",
    "sentiment_ds_test = Dataset.from_pandas(sentiment_df_test).remove_columns(\"__index_level_0__\")\n",
    "\n",
    "emotion_ds = DatasetDict({\n",
    "    'train': emotion_ds_train,\n",
    "    'test': emotion_ds_test\n",
    "})\n",
    "\n",
    "sentiment_ds = DatasetDict({\n",
    "    'train': sentiment_ds_train,\n",
    "    'test': sentiment_ds_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'emotion', 'label'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'emotion', 'label'],\n",
       "        num_rows: 1751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "other        2245\n",
       "disgust        68\n",
       "surprise       59\n",
       "happiness      50\n",
       "anger          47\n",
       "fear           26\n",
       "sadness         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "other        1572\n",
       "disgust        48\n",
       "surprise       41\n",
       "happiness      35\n",
       "anger          33\n",
       "fear           18\n",
       "sadness         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35556\n",
      "Accuracy for label happiness: 0.00000\n",
      "Accuracy for label anger: nan\n",
      "Accuracy for label disgust: 0.00000\n",
      "Accuracy for label fear: nan\n",
      "Accuracy for label sadness: nan\n",
      "Accuracy for label surprise: nan\n",
      "Accuracy for label other: 0.42105\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger    0.00000   0.00000   0.00000         0\n",
      "     disgust    0.00000   0.00000   0.00000         2\n",
      "   happiness    0.00000   0.00000   0.00000         5\n",
      "       other    0.84211   0.42105   0.56140        38\n",
      "    surprise    0.00000   0.00000   0.00000         0\n",
      "\n",
      "    accuracy                        0.35556        45\n",
      "   macro avg    0.16842   0.08421   0.11228        45\n",
      "weighted avg    0.71111   0.35556   0.47407        45\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  0  0  0  1  3]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0 10 16]]\n",
      "Accuracy: 0.62222\n",
      "Accuracy for label positive: 0.71429\n",
      "Accuracy for label negative: 1.00000\n",
      "Accuracy for label neutral: 0.53125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative    0.50000   1.00000   0.66667         6\n",
      "     neutral    0.89474   0.53125   0.66667        32\n",
      "    positive    0.35714   0.71429   0.47619         7\n",
      "\n",
      "    accuracy                        0.62222        45\n",
      "   macro avg    0.58396   0.74851   0.60317        45\n",
      "weighted avg    0.75848   0.62222   0.63704        45\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 5  0  2]\n",
      " [ 0  6  0]\n",
      " [ 9  6 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chaoming/anaconda3/envs/emotion_classification/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = predict(model, tokenizer, df_test)\n",
    "\n",
    "evaluate(df_test['emotion'], preds['emotion'], emotions)\n",
    "evaluate(df_test['sentiment'], preds['sentiment'], sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "ds = load_dataset(\"csv\", data_files=\"./data/drone/masked_all_tweets.csv\", split=\"train\")\n",
    "def transform_text(example):\n",
    "    example['text'] = generate_emotion_and_sentiment_prompt(example['text'])\n",
    "    return example\n",
    "# ds = ds.map(transform_text)\n",
    "# ds.map(generate_emotion_and_sentiment_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
